{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmMAvYFG5L9V1GWGpcST6l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavoNicodemos/Algoritmo_analise_resultado/blob/main/Algoritmo_Anlise_GUV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYmSxECgRUwk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import xgboost as xgb\n",
        "\n",
        "# ==============================================================\n",
        "# Função para simular dados contábeis (apenas para testes iniciais)\n",
        "# Substitua essa função pelo carregamento de seus dados reais\n",
        "# ==============================================================\n",
        "def simulate_accounting_data(n=500):\n",
        "    np.random.seed(42)\n",
        "    data = pd.DataFrame({\n",
        "        'data': pd.date_range('2024-01-01', periods=n, freq='D'),\n",
        "        'valor': np.random.normal(loc=1000, scale=300, size=n),\n",
        "        'historico': np.random.choice(['Salário', 'Aluguel', 'Energia', 'Vendas', 'Serviços'], n),\n",
        "        'centro_de_custo': np.random.choice(['ADM', 'VENDAS', 'TI'], n),\n",
        "        'codigo_aglutinacao': np.random.choice(['DRE01', 'DRE02', 'DRE03'], n)\n",
        "    })\n",
        "    return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# Classe principal para análise contábil automatizada\n",
        "# ==============================================================\n",
        "class AccountingAnalyzer:\n",
        "    def __init__(self):\n",
        "        # Modelos utilizados na análise\n",
        "        self.anomaly_detector = IsolationForest(n_estimators=100, contamination=0.05, random_state=42)\n",
        "        self.clusterer = MiniBatchKMeans(n_clusters=5, random_state=42)\n",
        "        self.encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "        self.classifier = xgb.XGBClassifier()\n",
        "        self.history = pd.DataFrame()  # Armazena dados já analisados\n",
        "\n",
        "    def analyze(self, new_data):\n",
        "        \"\"\"Executa a análise contábil nos dados fornecidos.\"\"\"\n",
        "        new_data = self._check_history(new_data)\n",
        "        features = self._preprocess(new_data)\n",
        "\n",
        "        # Detectar anomalias\n",
        "        new_data['anomaly'] = self.anomaly_detector.fit_predict(features)\n",
        "\n",
        "        # Agrupar em clusters\n",
        "        new_data['cluster'] = self.clusterer.fit_predict(features)\n",
        "\n",
        "        # Classificar tipo de problema se o modelo já foi treinado\n",
        "        if not self.history.empty and hasattr(self.classifier, 'classes_'):\n",
        "            model_features = self._create_features(new_data)\n",
        "            new_data['problem_type'] = self.classifier.predict(model_features)\n",
        "\n",
        "        # Atualiza o histórico\n",
        "        self._update_history(new_data)\n",
        "\n",
        "        # Retorna relatório consolidado\n",
        "        return self._generate_report(new_data)\n",
        "\n",
        "    def _check_history(self, data):\n",
        "        \"\"\"Remove dados já analisados anteriormente.\"\"\"\n",
        "        if self.history.empty:\n",
        "            return data\n",
        "        return data[~data.index.isin(self.history.index)]\n",
        "\n",
        "    def _preprocess(self, data):\n",
        "        \"\"\"Codifica dados categóricos e prepara os dados numéricos.\"\"\"\n",
        "        categorical_data = self.encoder.fit_transform(data[['centro_de_custo', 'codigo_aglutinacao']])\n",
        "        numerical_data = data[['valor']].values\n",
        "        return np.hstack([numerical_data, categorical_data])\n",
        "\n",
        "    def _create_features(self, data):\n",
        "        \"\"\"Gera features adicionais para o classificador.\"\"\"\n",
        "        categorical_data = self.encoder.transform(data[['centro_de_custo', 'codigo_aglutinacao']])\n",
        "        numerical_data = data[['valor', 'anomaly', 'cluster']].values\n",
        "        return np.hstack([numerical_data, categorical_data])\n",
        "\n",
        "    def _update_history(self, data):\n",
        "        \"\"\"Adiciona os dados analisados ao histórico.\"\"\"\n",
        "        self.history = pd.concat([self.history, data], ignore_index=True)\n",
        "\n",
        "    def _generate_explanations(self, data):\n",
        "        \"\"\"Gera justificativas automáticas para anomalias.\"\"\"\n",
        "        explanations = []\n",
        "        for _, row in data.iterrows():\n",
        "            if row['anomaly'] == -1:\n",
        "                explanations.append(f\"Valor atípico detectado em {row['centro_de_custo']} - {row['codigo_aglutinacao']}\")\n",
        "            else:\n",
        "                explanations.append(\"Sem anomalias.\")\n",
        "        return explanations\n",
        "\n",
        "    def _analyze_clusters(self, data):\n",
        "        \"\"\"Faz a análise dos agrupamentos por cluster.\"\"\"\n",
        "        return data.groupby(['cluster', 'codigo_aglutinacao']).agg({'valor': ['mean', 'count']}).reset_index()\n",
        "\n",
        "    def _generate_report(self, data):\n",
        "        \"\"\"Compila o relatório final da análise.\"\"\"\n",
        "        return {\n",
        "            'anomalies': data[data['anomaly'] == -1],\n",
        "            'cluster_analysis': self._analyze_clusters(data),\n",
        "            'explanations': self._generate_explanations(data)\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "fiCQwhzjRy2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# Execução de exemplo (substituir simulate_accounting_data por dados reais)\n",
        "# ==============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    dados_simulados = simulate_accounting_data()\n",
        "    analisador = AccountingAnalyzer()\n",
        "    relatorio = analisador.analyze(dados_simulados)\n",
        "\n",
        "    # Armazena os dados em variáveis para visualização\n",
        "    anomalias_df = relatorio['anomalies']\n",
        "    clusters_df = relatorio['cluster_analysis']\n",
        "    explicacoes_df = pd.DataFrame({'explicacao': relatorio['explanations']})\n",
        "\n",
        "    # Exibe como DataFrames\n",
        "    display(anomalias_df.head())\n",
        "    display(clusters_df.head())\n",
        "    display(explicacoes_df.head())"
      ],
      "metadata": {
        "id": "ipN3LzywR60M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}