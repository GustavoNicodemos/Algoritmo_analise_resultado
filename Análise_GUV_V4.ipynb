{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustavoNicodemos/Algoritmo_analise_resultado/blob/main/An%C3%A1lise_GUV_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IVpb5KAWg6dJ",
        "outputId": "06f759b9-5b99-465a-9c30-b8a7cf79019d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyxlsb\n",
            "  Downloading pyxlsb-1.0.10-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Downloading pyxlsb-1.0.10-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyxlsb\n",
            "Successfully installed pyxlsb-1.0.10\n"
          ]
        }
      ],
      "source": [
        "# Instale o pacote necessário\n",
        "!pip install pyxlsb openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vwn5doODLZk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdzWSN4HDP_0"
      },
      "outputs": [],
      "source": [
        "class AccountingAnalyzer:\n",
        "    def __init__(self, historical_data):\n",
        "        self.historical_data = historical_data.copy()\n",
        "\n",
        "    def _consolidate_data(self, df):\n",
        "        return df.groupby(['Cost_Center', 'Group_Account']).agg({'Amount_in_LC': 'sum'}).reset_index()\n",
        "\n",
        "    def _detect_significant_variations(self, new_data):\n",
        "        consolidated_new = self._consolidate_data(new_data)\n",
        "        consolidated_hist = self._consolidate_data(self.historical_data)\n",
        "\n",
        "        historical_std = self.historical_data.groupby(['Cost_Center', 'Group_Account'])['Amount_in_LC'].std().reset_index()\n",
        "        historical_std.columns = ['Cost_Center', 'Group_Account', 'std_dev']\n",
        "\n",
        "        comparativo = pd.merge(consolidated_new, consolidated_hist, on=['Cost_Center', 'Group_Account'], how='left', suffixes=('', '_hist'))\n",
        "        comparativo = pd.merge(comparativo, historical_std, on=['Cost_Center', 'Group_Account'], how='left')\n",
        "\n",
        "        comparativo['std_dev'] = comparativo['std_dev'].fillna(0)\n",
        "        comparativo['Amount_in_LC_hist'] = comparativo['Amount_in_LC_hist'].fillna(0)\n",
        "\n",
        "        comparativo['absolute_variation'] = comparativo['Amount_in_LC'] - comparativo['Amount_in_LC_hist']\n",
        "        comparativo['percent_variation'] = np.where(\n",
        "            comparativo['Amount_in_LC_hist'] != 0,\n",
        "            (comparativo['absolute_variation'] / comparativo['Amount_in_LC_hist']) * 100,\n",
        "            np.nan\n",
        "        )\n",
        "\n",
        "        comparativo['relevant'] = (comparativo['absolute_variation'] > comparativo['std_dev'] * 1.5) | \\\n",
        "                                  (comparativo['absolute_variation'] < -comparativo['std_dev'] * 1.5)\n",
        "\n",
        "        detalhes_variacoes = comparativo[['Cost_Center', 'Group_Account', 'Amount_in_LC', 'Amount_in_LC_hist',\n",
        "                                          'absolute_variation', 'percent_variation', 'std_dev', 'relevant']]\n",
        "\n",
        "        variacoes_relevantes = comparativo[comparativo['relevant'] == True]\n",
        "\n",
        "        return variacoes_relevantes, detalhes_variacoes\n",
        "\n",
        "    def _detectar_lancamentos_explicativos(self, df_novo, df_historico, relevantes):\n",
        "        explicativos = []\n",
        "\n",
        "        for _, linha in relevantes.iterrows():\n",
        "            cc = linha['Cost_Center']\n",
        "            conta = linha['Group_Account']\n",
        "\n",
        "            hist_lanc = df_historico[(df_historico['Cost_Center'] == cc) & (df_historico['Group_Account'] == conta)]\n",
        "            novos_lanc = df_novo[(df_novo['Cost_Center'] == cc) & (df_novo['Group_Account'] == conta)]\n",
        "\n",
        "            if hist_lanc.empty or novos_lanc.empty:\n",
        "                continue\n",
        "\n",
        "            media = hist_lanc['Amount_in_LC'].mean()\n",
        "            std = hist_lanc['Amount_in_LC'].std()\n",
        "\n",
        "            limiar = media + 1.5 * std\n",
        "\n",
        "            for _, lanc in novos_lanc.iterrows():\n",
        "                if lanc['Amount_in_LC'] > limiar or lanc['Amount_in_LC'] < -limiar:\n",
        "                    explicativos.append(lanc)\n",
        "\n",
        "        return pd.DataFrame(explicativos)\n",
        "\n",
        "    def _generate_explanations(self, df):\n",
        "        explanations = []\n",
        "        for _, row in df.iterrows():\n",
        "            if row.get('anomaly', 0) == -1:\n",
        "                explanations.append(f\"Anomalia isolada em {row['Group_Account']} no CC {row['Cost_Center']}\")\n",
        "            elif pd.notnull(row.get('percent_variation')) and abs(row['percent_variation']) > 10:\n",
        "                explanations.append(f\"Variação de {row['percent_variation']:.2f}% em {row['Group_Account']} no CC {row['Cost_Center']}\")\n",
        "            else:\n",
        "                explanations.append(\"Sem variações significativas.\")\n",
        "        return explanations\n",
        "\n",
        "    def analyze(self, new_data):\n",
        "        consolidated_data = self._consolidate_data(new_data)\n",
        "\n",
        "        modelo = IsolationForest(contamination=0.05, random_state=42)\n",
        "        dados_para_modelo = pd.get_dummies(consolidated_data[['Cost_Center', 'Group_Account']])\n",
        "        modelo.fit(dados_para_modelo)\n",
        "        consolidated_data['anomaly'] = modelo.predict(dados_para_modelo)\n",
        "\n",
        "        variacoes_relevantes, detalhes_variacoes = self._detect_significant_variations(new_data)\n",
        "        explicativos_df = self._detectar_lancamentos_explicativos(new_data, self.historical_data, variacoes_relevantes)\n",
        "\n",
        "        new_data['explanation'] = self._generate_explanations(new_data)\n",
        "\n",
        "        return {\n",
        "            'anomalias_df': explicativos_df,\n",
        "            'consolidated_df': consolidated_data,\n",
        "            'explicacoes_df': new_data[['Group_Account', 'explanation']],\n",
        "            'variacoes_relevantes': variacoes_relevantes,\n",
        "            'detalhes_variacoes': detalhes_variacoes\n",
        "        }\n",
        "    def analisar_variacoes_por_lancamento(self, df):\n",
        "        df_proc = df.copy()\n",
        "        df_proc['Mês'] = pd.to_datetime(df_proc['PERÍODO']).dt.to_period('M')\n",
        "\n",
        "        # Cálculo da média e desvio padrão por conta\n",
        "        stats = self.historical_data.groupby('Group_Account')['Amount_in_LC'].agg(['mean', 'std']).reset_index()\n",
        "        stats = stats.rename(columns={'mean': 'media_historica', 'std': 'desvio_padrao'})\n",
        "\n",
        "        # Agrega valor atual por conta\n",
        "        valores_atuais = df_proc.groupby('Group_Account')['Amount_in_LC'].sum().reset_index()\n",
        "        base_comparada = valores_atuais.merge(stats, on='Group_Account', how='left')\n",
        "        base_comparada['var_relevante'] = abs(base_comparada['Amount_in_LC'] - base_comparada['media_historica']) > 2 * base_comparada['desvio_padrao']\n",
        "\n",
        "        contas_relevantes = base_comparada[base_comparada['var_relevante']]['Group_Account'].tolist()\n",
        "\n",
        "        # Dentro das contas com variação relevante, procura os lançamentos que mais contribuíram\n",
        "        df_filtrado = df_proc[df_proc['Group_Account'].isin(contas_relevantes)].copy()\n",
        "        df_filtrado['abs_valor'] = df_filtrado['Amount_in_LC'].abs()\n",
        "\n",
        "        top_lancamentos = (\n",
        "            df_filtrado\n",
        "            .groupby(['Group_Account', 'Text', 'Cost_Center'])\n",
        "            .agg(qtd=('Amount_in_LC', 'count'),\n",
        "                 soma_valor=('Amount_in_LC', 'sum'),\n",
        "                 soma_abs=('abs_valor', 'sum'))\n",
        "            .reset_index()\n",
        "            .sort_values(['Group_Account', 'soma_abs'], ascending=[True, False])\n",
        "        )\n",
        "\n",
        "        return top_lancamentos, base_comparada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf9xpa7ZDXHi",
        "outputId": "5e261a3f-6c74-47bc-de69-a3524850deaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Planilha final gerada com múltiplas abas, incluindo análise aprofundada de variações.\n"
          ]
        }
      ],
      "source": [
        "# Execução no Colab\n",
        "if __name__ == \"__main__\":\n",
        "    base_dados = pd.read_excel('Dados_GUV.xlsb')\n",
        "    dados_historicos = pd.read_excel('Dados_historicos_GUV.xlsb')\n",
        "\n",
        "    analisador = AccountingAnalyzer(historical_data=dados_historicos)\n",
        "\n",
        "    relatorio = analisador.analyze(base_dados)\n",
        "\n",
        "    # Novo método de análise de lançamentos responsáveis por variações\n",
        "    lancamentos_relevantes, resumo_relevantes = analisador.analisar_variacoes_por_lancamento(base_dados)\n",
        "\n",
        "    # Exportação para Excel com todas as abas\n",
        "    with pd.ExcelWriter('Relatorio_Contabil_Analitico_Completo.xlsx') as writer:\n",
        "        relatorio['anomalias_df'].to_excel(writer, sheet_name='Anomalias', index=False)\n",
        "        relatorio['consolidated_df'].to_excel(writer, sheet_name='Consolidado_DRE', index=False)\n",
        "        relatorio['explicacoes_df'].drop_duplicates().to_excel(writer, sheet_name='Explicacoes', index=False)\n",
        "        relatorio['variacoes_relevantes'].to_excel(writer, sheet_name='Variacoes_Relevantes', index=False)\n",
        "        relatorio['detalhes_variacoes'].to_excel(writer, sheet_name='Detalhamento_Lancamentos', index=False)\n",
        "        lancamentos_relevantes.to_excel(writer, sheet_name='Lancamentos_Relevantes', index=False)\n",
        "        resumo_relevantes.to_excel(writer, sheet_name='Resumo_Por_Centro_Conta', index=False)\n",
        "\n",
        "    print(\"✅ Planilha final gerada com múltiplas abas, incluindo análise aprofundada de variações.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Verifica se o arquivo foi criado\n",
        "print(os.listdir())\n",
        "from google.colab import files\n",
        "files.download('Relatorio_Contabil_Analitico_Completo.xlsx')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "I5T45C38iqmu",
        "outputId": "a2b470a6-f58a-42fc-afd7-0884ce264df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', '.ipynb_checkpoints', 'Dados_GUV.xlsb', 'Relatorio_Contabil_Analitico_Completo.xlsx', 'Dados_historicos_GUV.xlsb', 'sample_data']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_229e6aa3-4499-4f13-b068-04106bb09ad9\", \"Relatorio_Contabil_Analitico_Completo.xlsx\", 290215)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7oQs/drPlf0C5ztTEJJx9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}